{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnibZvco7i1o"
      },
      "source": [
        "# <font color='#11a642' size='6'> **Построение моделей**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrow0r8B7rEa"
      },
      "source": [
        "## <font color='#11a642' size='5'> Построение модели **Random Forest**. Гиперпараметры подберите либо вручную, либо с помощью GridSearchCV или RandomizedSearchCV\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxWLcCFwXzGc"
      },
      "source": [
        "- необходимо ли обрабатывать категориальные признаки заранее?\n",
        "- необходимо ли обрабатывать пропуски?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCOomVx_7wGJ"
      },
      "outputs": [],
      "source": [
        "# ваш код\n",
        "rf_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', RandomForestRegressor(random_state=42, n_jobs=-1))\n",
        "])\n",
        "\n",
        "# Упрощенный поиск параметров\n",
        "param_grid_rf = {\n",
        "    'regressor__n_estimators': [50, 100],  # Уменьшили количество деревьев\n",
        "    'regressor__max_depth': [10, 20],      # Ограничили глубину\n",
        "    'regressor__min_samples_split': [5, 10]\n",
        "}\n",
        "\n",
        "print(\"Начинаем GridSearch для Random Forest...\")\n",
        "grid_search_rf = GridSearchCV(\n",
        "    rf_pipeline, \n",
        "    param_grid_rf, \n",
        "    cv=3,  # Уменьшили количество фолдов\n",
        "    scoring='neg_mean_squared_error', \n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "\n",
        "# Оценка\n",
        "best_rf = grid_search_rf.best_estimator_\n",
        "y_pred_rf = best_rf.predict(X_test)\n",
        "\n",
        "print(\"\\nRandom Forest Results:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred_rf):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred_rf):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_rf)):.4f}\")\n",
        "print(f\"R2: {r2_score(y_test, y_pred_rf):.4f}\")\n",
        "print(f\"Best params: {grid_search_rf.best_params_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS8enPrk7wP7"
      },
      "source": [
        "## <font color='#11a642' size='5'> Построение модели бустинга **XGBoost**. Гиперпараметры подберите либо вручную, либо с помощью GridSearchCV или RandomizedSearchCV\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCWHzHHYXyYd"
      },
      "source": [
        "- необходимо ли обрабатывать категориальные признаки заранее?\n",
        "- необходимо ли обрабатывать пропуски?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyKuh45f8Ff3"
      },
      "outputs": [],
      "source": [
        "# ваш код\n",
        "xgb_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', XGBRegressor(random_state=42, n_jobs=-1, verbosity=0))\n",
        "])\n",
        "\n",
        "# Более реалистичные параметры для XGBoost\n",
        "param_dist_xgb = {\n",
        "    'regressor__n_estimators': [100, 200],\n",
        "    'regressor__learning_rate': [0.1, 0.2],\n",
        "    'regressor__max_depth': [3, 6],\n",
        "    'regressor__subsample': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "print(\"Начинаем RandomizedSearch для XGBoost...\")\n",
        "random_search_xgb = RandomizedSearchCV(\n",
        "    xgb_pipeline, \n",
        "    param_dist_xgb, \n",
        "    n_iter=8,  # Уменьшили количество итераций\n",
        "    cv=3, \n",
        "    scoring='neg_mean_squared_error', \n",
        "    random_state=42, \n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "random_search_xgb.fit(X_train, y_train)\n",
        "\n",
        "# Оценка\n",
        "best_xgb = random_search_xgb.best_estimator_\n",
        "y_pred_xgb = best_xgb.predict(X_test)\n",
        "\n",
        "print(\"\\nXGBoost Results:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred_xgb):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred_xgb):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_xgb)):.4f}\")\n",
        "print(f\"R2: {r2_score(y_test, y_pred_xgb):.4f}\")\n",
        "print(f\"Best params: {random_search_xgb.best_params_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e93XQW3aW8VG"
      },
      "source": [
        "## <font color='#11a642' size='5'> Построение модели бустинга **LightGBM**. Гиперпараметры подберите либо вручную, либо с помощью GridSearchCV или RandomizedSearchCV\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjytc2azXxzl"
      },
      "source": [
        "- необходимо ли обрабатывать категориальные признаки заранее?\n",
        "- необходимо ли обрабатывать пропуски?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1qxGRN_W7sU"
      },
      "outputs": [],
      "source": [
        "# ваш код\n",
        "lgbm_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', LGBMRegressor(random_state=42, n_jobs=-1, verbosity=-1))\n",
        "])\n",
        "\n",
        "param_dist_lgbm = {\n",
        "    'regressor__n_estimators': [100, 200],\n",
        "    'regressor__learning_rate': [0.1, 0.2],\n",
        "    'regressor__num_leaves': [31, 62],\n",
        "    'regressor__feature_fraction': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "print(\"Начинаем RandomizedSearch для LightGBM...\")\n",
        "random_search_lgbm = RandomizedSearchCV(\n",
        "    lgbm_pipeline, \n",
        "    param_dist_lgbm, \n",
        "    n_iter=8, \n",
        "    cv=3, \n",
        "    scoring='neg_mean_squared_error', \n",
        "    random_state=42, \n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "random_search_lgbm.fit(X_train, y_train)\n",
        "\n",
        "# Оценка\n",
        "best_lgbm = random_search_lgbm.best_estimator_\n",
        "y_pred_lgbm = best_lgbm.predict(X_test)\n",
        "\n",
        "print(\"\\nLightGBM Results:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred_lgbm):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred_lgbm):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_lgbm)):.4f}\")\n",
        "print(f\"R2: {r2_score(y_test, y_pred_lgbm):.4f}\")\n",
        "print(f\"Best params: {random_search_lgbm.best_params_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8H_vpiTXBqv"
      },
      "source": [
        "## <font color='#11a642' size='5'> Построение модели бустинга **Catboost**. Гиперпараметры подберите либо вручную, либо с помощью GridSearchCV или RandomizedSearchCV\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nn3E55jXZLs"
      },
      "source": [
        "- необходимо ли обрабатывать категориальные признаки заранее?\n",
        "- необходимо ли обрабатывать пропуски?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNGfYsWkXHcy"
      },
      "outputs": [],
      "source": [
        "# ваш код\n",
        "# Подготовим данные специально для CatBoost\n",
        "X_train_cat = X_train.copy()\n",
        "X_test_cat = X_test.copy()\n",
        "\n",
        "# Обработаем пропуски только для числовых признаков\n",
        "for col in num_features:\n",
        "    X_train_cat[col].fillna(X_train_cat[col].median(), inplace=True)\n",
        "    X_test_cat[col].fillna(X_train_cat[col].median(), inplace=True)\n",
        "\n",
        "# Для категориальных признаков CatBoost обработает сам\n",
        "for col in cat_features:\n",
        "    X_train_cat[col].fillna('Unknown', inplace=True)\n",
        "    X_test_cat[col].fillna('Unknown', inplace=True)\n",
        "\n",
        "# Определяем индексы категориальных признаков\n",
        "cat_features_indices = [X_train_cat.columns.get_loc(c) for c in cat_features]\n",
        "\n",
        "# Простая модель CatBoost без пайплайна\n",
        "catboost_model = CatBoostRegressor(\n",
        "    iterations=200,  \n",
        "    learning_rate=0.1,\n",
        "    depth=6,\n",
        "    cat_features=cat_features_indices,\n",
        "    random_state=42,\n",
        "    verbose=50  \n",
        ")\n",
        "\n",
        "print(\"Начинаем обучение CatBoost...\")\n",
        "catboost_model.fit(X_train_cat, y_train)\n",
        "\n",
        "# Оценка\n",
        "y_pred_cat = catboost_model.predict(X_test_cat)\n",
        "\n",
        "print(\"\\nCatBoost Results:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred_cat):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred_cat):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_cat)):.4f}\")\n",
        "print(f\"R2: {r2_score(y_test, y_pred_cat):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYLNz1JrZGlz"
      },
      "source": [
        "## <font color='#11a642' size='5'> Выводы:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYkuh5P2Xzsi"
      },
      "source": [
        "### <font color='#11a642' size='4'>\n",
        "- Какая модель оказалась более стабильной и лучше по метрикам?\n",
        "- Какая модель требует меньше дополнительных обработок данных?\n",
        "- Какую модель вы выбираете и почему?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- По результатам оценки метрик (MAE, MSE, R2) лучшей моделью оказалась CatBoost.\n",
        "- CatBoost требует меньше всего предварительной обработки данных, так как он автоматически обрабатывает категориальные признаки и устойчив к пропускам.\n",
        "- CatBoost, так как он показал наилучшие результаты по метрикам, требует минимальной предварительной обработки данных и обладает хорошей устойчивостью к переобучению. Также CatBoost имеет встроенную обработку категориальных признаков, что упрощает процесс моделировани"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
